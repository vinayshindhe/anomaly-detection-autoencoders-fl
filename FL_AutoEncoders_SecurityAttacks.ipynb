{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "yuxwJynwgiYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fcfa86b0-b7eb-46fd-e3f7-1fe49ab01601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flower\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2PqWBD2899WQ",
        "outputId": "8c42867a-d778-4e23-d0b5-0b046cb138d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flower\n",
            "  Downloading flower-2.0.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting celery>=5.0.5 (from flower)\n",
            "  Downloading celery-5.5.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tornado<7.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from flower) (6.4.2)\n",
            "Requirement already satisfied: prometheus-client>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from flower) (0.21.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from flower) (4.12.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from flower) (2025.2)\n",
            "Collecting billiard<5.0,>=4.2.1 (from celery>=5.0.5->flower)\n",
            "  Downloading billiard-4.2.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting kombu<5.6,>=5.5.2 (from celery>=5.0.5->flower)\n",
            "  Downloading kombu-5.5.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting vine<6.0,>=5.1.0 (from celery>=5.0.5->flower)\n",
            "  Downloading vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0,>=8.1.2 in /usr/local/lib/python3.11/dist-packages (from celery>=5.0.5->flower) (8.2.0)\n",
            "Collecting click-didyoumean>=0.3.0 (from celery>=5.0.5->flower)\n",
            "  Downloading click_didyoumean-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting click-repl>=0.2.0 (from celery>=5.0.5->flower)\n",
            "  Downloading click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting click-plugins>=1.1.1 (from celery>=5.0.5->flower)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from celery>=5.0.5->flower) (2.9.0.post0)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.36 in /usr/local/lib/python3.11/dist-packages (from click-repl>=0.2.0->celery>=5.0.5->flower) (3.0.51)\n",
            "Collecting amqp<6.0.0,>=5.1.1 (from kombu<5.6,>=5.5.2->celery>=5.0.5->flower)\n",
            "  Downloading amqp-5.3.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: tzdata>=2025.2 in /usr/local/lib/python3.11/dist-packages (from kombu<5.6,>=5.5.2->celery>=5.0.5->flower) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->celery>=5.0.5->flower) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery>=5.0.5->flower) (0.2.13)\n",
            "Downloading flower-2.0.1-py2.py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading celery-5.5.2-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.6/438.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading billiard-4.2.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading click_repl-0.3.0-py3-none-any.whl (10 kB)\n",
            "Downloading kombu-5.5.3-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.9/209.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vine-5.1.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading amqp-5.3.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vine, click-plugins, click-didyoumean, billiard, click-repl, amqp, kombu, celery, flower\n",
            "Successfully installed amqp-5.3.1 billiard-4.2.1 celery-5.5.2 click-didyoumean-0.3.1 click-plugins-1.1.1 click-repl-0.3.0 flower-2.0.1 kombu-5.5.3 vine-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y flwr ray\n",
        "!pip install -U \"flwr[simulation]\" --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Sgepk8g-PcI",
        "outputId": "16ad8966-aad0-40ab-e871-55e77bd332d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping flwr as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping ray as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.0/540.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KoO2d3kO4lEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC3cM21UlsHo",
        "outputId": "1e2c2f98-45b9-44c5-c49d-2a2c0bab0944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "\n",
        "!unzip /content/N-BAIoT\\ Dataset.zip\n"
      ],
      "metadata": {
        "id": "1-aZhzVUghrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6d2fb671-94d1-4562-f154-0cd25e6da01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/N-BAIoT Dataset.zip\n",
            "   creating: N-BAIoT Dataset/\n",
            "  inflating: N-BAIoT Dataset/.DS_Store  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/._.DS_Store  \n",
            "   creating: N-BAIoT Dataset/benign/\n",
            "   creating: N-BAIoT Dataset/1/\n",
            "   creating: N-BAIoT Dataset/2/\n",
            "  inflating: N-BAIoT Dataset/benign/1.benign.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/benign/._1.benign.csv  \n",
            "  inflating: N-BAIoT Dataset/benign/2.benign.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/benign/._2.benign.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.gafgyt.combo.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.gafgyt.combo.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.mirai.scan.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.mirai.scan.csv  \n",
            "  inflating: N-BAIoT Dataset/1/.DS_Store  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._.DS_Store  \n",
            "  inflating: N-BAIoT Dataset/1/1.gafgyt.scan.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.gafgyt.scan.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.gafgyt.udp.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.gafgyt.udp.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.gafgyt.tcp.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.gafgyt.tcp.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.mirai.ack.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.mirai.ack.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.mirai.udp.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.mirai.udp.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.mirai.syn.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.mirai.syn.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.mirai.udpplain.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.mirai.udpplain.csv  \n",
            "  inflating: N-BAIoT Dataset/1/1.gafgyt.junk.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/1/._1.gafgyt.junk.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.gafgyt.udp.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.gafgyt.udp.csv  \n",
            "  inflating: N-BAIoT Dataset/2/.DS_Store  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._.DS_Store  \n",
            "  inflating: N-BAIoT Dataset/2/2.gafgyt.tcp.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.gafgyt.tcp.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.mirai.scan.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.mirai.scan.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.gafgyt.junk.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.gafgyt.junk.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.mirai.udp.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.mirai.udp.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.gafgyt.scan.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.gafgyt.scan.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.mirai.ack.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.mirai.ack.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.gafgyt.combo.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.gafgyt.combo.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.mirai.syn.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.mirai.syn.csv  \n",
            "  inflating: N-BAIoT Dataset/2/2.mirai.udpplain.csv  \n",
            "  inflating: __MACOSX/N-BAIoT Dataset/2/._2.mirai.udpplain.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "def preprocess_data(numeric_df):\n",
        "\n",
        "    for column in numeric_df.columns:\n",
        "        if numeric_df[column].dtype == object:  # Check for string/object type columns\n",
        "            try:\n",
        "                numeric_df[column] = pd.to_numeric(numeric_df[column], errors='coerce')\n",
        "            except ValueError:\n",
        "                print(f\"Column '{column}' contains non-numeric values. Applying One-Hot Encoding.\")\n",
        "\n",
        "            if numeric_df[column].dtype == object or numeric_df[column].isnull().any():\n",
        "               # One-Hot Encoding for categorical columns\n",
        "                encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "                # Create encoder instance\n",
        "\n",
        "                valid_rows = numeric_df[column].apply(lambda x: pd.api.types.is_number(x) or isinstance(x, str))\n",
        "                numeric_df = numeric_df[valid_rows]  # Keep only valid rows\n",
        "\n",
        "\n",
        "                encoded_data = encoder.fit_transform(numeric_df[[column]])\n",
        "                encoded_df = pd.DataFrame(encoded_data, columns=[f\"{column}_{val}\" for val in encoder.categories_[0]])\n",
        "                numeric_df = pd.concat([numeric_df, encoded_df], axis=1)\n",
        "                numeric_df.drop(column, axis=1, inplace=True) # remove original column\n",
        "\n",
        "    # Scale the Data\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(numeric_df.values)\n",
        "\n",
        "    return scaled_data, scaler\n",
        "\n"
      ],
      "metadata": {
        "id": "gca3c3Djx7lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            #nn.Linear(input_dim, 512),\n",
        "            #nn.ReLU(),\n",
        "            #nn.BatchNorm1d(512),\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, input_dim),\n",
        "            #nn.ReLU(),\n",
        "            #nn.BatchNorm1d(512),\n",
        "            #nn.Linear(512, input_dim),\n",
        "            nn.Tanh()  # Final activation to match normalized input range\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ],
      "metadata": {
        "id": "3BFAh4yZ085Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, Tuple\n",
        "import torch\n",
        "\n",
        "class AutoencoderClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, trainloader, testloader, device):\n",
        "        self.model = model\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.device = device\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        # Return model parameters as a list of NumPy arrays\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        # Set model parameters from a list of NumPy arrays\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Set model parameters, train locally, and return updated parameters\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.train()\n",
        "        self.model.to(self.device)\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters())\n",
        "\n",
        "        epochs = config[\"epochs\"]\n",
        "        for _ in range(epochs):\n",
        "            for batch_idx, (data, _) in enumerate(self.trainloader):\n",
        "                data = data.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(data)\n",
        "                loss = criterion(outputs, data)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        return self.get_parameters({}), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # Set model parameters, evaluate locally, and return loss and metrics\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.eval()\n",
        "        self.model.to(self.device)\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, _ in self.testloader:\n",
        "                data = data.to(self.device)\n",
        "                outputs = self.model(data)\n",
        "                loss = criterion(outputs, data)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(self.testloader), len(self.testloader.dataset), {\"loss\": total_loss / len(self.testloader)}"
      ],
      "metadata": {
        "id": "_vgk3PYl31vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aMC1lnz05L9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "def load_client_data(client_data, client_loaders):\n",
        "  train_df, test_df = train_test_split(client_data, test_size=0.2, random_state=42)\n",
        "  train_data_t = torch.tensor(train_df, dtype=torch.float32)\n",
        "  test_data_t = torch.tensor(test_df, dtype=torch.float32)\n",
        "\n",
        "  train_dataset = TensorDataset(train_data_t, torch.zeros_like(train_data_t))\n",
        "  test_dataset = TensorDataset(test_data_t, torch.zeros_like(test_data_t))\n",
        "\n",
        "  trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "  testloader = DataLoader(test_dataset, batch_size=32)\n",
        "  client_loaders.append((trainloader, testloader))\n",
        "  return client_loaders\n",
        "\n",
        "\n",
        "\n",
        "df_1 = pd.read_csv(\"/content/N-BAIoT Dataset/benign/1.benign.csv\")\n",
        "df_2 = pd.read_csv(\"/content/N-BAIoT Dataset/benign/2.benign.csv\")\n",
        "\n",
        "data_1, scaler_1 = preprocess_data(df_1)\n",
        "data_1 = np.nan_to_num(data_1, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "data_2, scaler_2 = preprocess_data(df_2)\n",
        "data_2 = np.nan_to_num(data_2, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "client_loaders = []\n",
        "client_loaders = load_client_data(data_1, client_loaders)\n",
        "client_loaders = load_client_data(data_2, client_loaders)\n",
        "\n"
      ],
      "metadata": {
        "id": "lA0kaidb5xJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> fl.client.NumPyClient:\n",
        "    \"\"\"Create a Flower client with its own data partition.\"\"\"\n",
        "    # Get the data loaders for this client\n",
        "    trainloader, testloader = client_loaders[int(cid)]\n",
        "\n",
        "    # Create a new Autoencoder model for each client\n",
        "    input_dim = trainloader.dataset[0][0].shape[0]\n",
        "    model = Autoencoder(input_dim)\n",
        "\n",
        "    # Use CPU for simplicity in this example\n",
        "    device = torch.device(\"cpu\")\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"Client {cid}: Using device {device}\")\n",
        "    # Create and return the client\n",
        "    return AutoencoderClient(model, trainloader, testloader, device)"
      ],
      "metadata": {
        "id": "lSZttskR5WDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"This is a custom strategy that behaves exactly like\n",
        "    FedAvg with the difference of storing of the state of\n",
        "    the global model to disk after each round.\n",
        "    \"\"\"\n",
        "\n",
        "from logging import INFO\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from flwr.common.logger import log\n",
        "from flwr.common import parameters_to_ndarrays\n",
        "\n",
        "class FedAvgWithModelSaving(fl.server.strategy.FedAvg):\n",
        "\n",
        "    def __init__(self, save_path: str, *args, **kwargs):\n",
        "        self.save_path = Path(save_path)\n",
        "        # Create directory if needed\n",
        "        self.save_path.mkdir(exist_ok=True, parents=True)\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def _save_global_model(self, server_round: int, parameters):\n",
        "\n",
        "        # convert parameters to list of NumPy arrays\n",
        "        # this will make things easy if you want to load them into a\n",
        "        # PyTorch or TensorFlow model later\n",
        "        ndarrays = parameters_to_ndarrays(parameters)\n",
        "        data = {'globa_parameters': ndarrays}\n",
        "        filename = str(self.save_path/f\"parameters_round_{server_round}.pkl\")\n",
        "        with open(filename, 'wb') as h:\n",
        "            pickle.dump(data, h, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        log(INFO, f\"Checkpoint saved to: {filename}\")\n",
        "\n",
        "    def evaluate(self, server_round: int, parameters):\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        # save the parameters to disk using a custom method\n",
        "        self._save_global_model(server_round, parameters)\n",
        "\n",
        "        # call the parent method so evaluation is performed as\n",
        "        # FedAvg normally does.\n",
        "        return super().evaluate(server_round, parameters)"
      ],
      "metadata": {
        "id": "SexL3ZIbMUUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Simulation\n",
        "\n",
        "s_strategy = FedAvgWithModelSaving(\n",
        "    save_path='my_checkpoints',\n",
        "    # These functions are now passed directly to your custom strategy's constructor\n",
        "    on_fit_config_fn=lambda server_round: {\"epochs\": 5},\n",
        "    on_evaluate_config_fn=lambda server_round: {\"epochs\": 5},\n",
        ")\n",
        "\n",
        "# Start the simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=2),  # Number of federated learning rounds\n",
        "    # strategy=fl.server.strategy.FedAvg() # Default strategy is FedAvg\n",
        "    strategy=s_strategy,\n",
        "  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RoG8MqJl7ZJL",
        "outputId": "56db0953-57bc-4e0d-bedf-753f3a8f7363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=4, no round_timeout\n",
            "2025-05-19 13:45:16,580\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7884801639.0, 'object_store_memory': 3942400819.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=7642)\u001b[0m 2025-05-19 13:45:22.066634: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=7642)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=7642)\u001b[0m E0000 00:00:1747662322.116464    7642 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=7642)\u001b[0m E0000 00:00:1747662322.129930    7642 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(pid=7641)\u001b[0m 2025-05-19 13:45:22.167462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=7641)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=7641)\u001b[0m E0000 00:00:1747662322.226573    7641 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=7641)\u001b[0m E0000 00:00:1747662322.238895    7641 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Checkpoint saved to: my_checkpoints/parameters_round_0.pkl\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m Client 0: Using device cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m Client 1: Using device cpu\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m Client 0: Using device cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      Checkpoint saved to: my_checkpoints/parameters_round_1.pkl\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m Client 0: Using device cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      Checkpoint saved to: my_checkpoints/parameters_round_2.pkl\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m Client 0: Using device cpu\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      Checkpoint saved to: my_checkpoints/parameters_round_3.pkl\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m Client 0: Using device cpu\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      Checkpoint saved to: my_checkpoints/parameters_round_4.pkl\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=7641)\u001b[0m         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=7642)\u001b[0m Client 1: Using device cpu\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 4 round(s) in 155.29s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.006671192784447174\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.003644005338117049\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.005800796566598579\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.004408530003833113\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.006671192784447174\n",
              "\tround 2: 0.003644005338117049\n",
              "\tround 3: 0.005800796566598579\n",
              "\tround 4: 0.004408530003833113"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the threshold based on reconstruction errors on the training benign data.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "import torch\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Load the trained model ---\n",
        "\n",
        "checkpoint_path = 'my_checkpoints/parameters_round_2.pkl' # Adjust if needed\n",
        "\n",
        "# Load the checkpoint data\n",
        "with open(checkpoint_path, 'rb') as h:\n",
        "    checkpoint_data = pickle.load(h)\n",
        "\n",
        "# Extract the global parameters\n",
        "global_parameters_ndarrays = checkpoint_data['globa_parameters']\n",
        "\n",
        "# Initialize a new Autoencoder model\n",
        "input_dim = data_1.shape[1] # Use the dimension from the training data\n",
        "\n",
        "autoencoder_inference = Autoencoder(input_dim)\n",
        "\n",
        "# Create OrderedDict to load state_dict\n",
        "temp_model = Autoencoder(input_dim) # Create a temporary model to get state_dict keys\n",
        "state_dict_keys = list(temp_model.state_dict().keys())\n",
        "loaded_state_dict = OrderedDict(zip(state_dict_keys, [torch.tensor(v) for v in global_parameters_ndarrays]))\n",
        "\n",
        "# Load the state dictionary\n",
        "autoencoder_inference.load_state_dict(loaded_state_dict)\n",
        "autoencoder_inference.eval() # Set model to evaluation mode\n",
        "\n",
        "\n",
        "# --- Calculate Reconstruction Errors on Benign Training Data to Determine Threshold ---\n",
        "\n",
        "benign_training_errors = []\n",
        "criterion = nn.MSELoss() # Use standard MSELoss for calculating error per data point\n",
        "\n",
        "# Access the original benign training data used for client 0 and client 1\n",
        "all_benign_training_data = torch.cat((torch.tensor(data_1, dtype=torch.float32), torch.tensor(data_2, dtype=torch.float32)), dim=0)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(all_benign_training_data.shape[0]):\n",
        "        data_point = all_benign_training_data[i].unsqueeze(0)\n",
        "        output = autoencoder_inference(data_point)\n",
        "        loss = criterion(output, data_point)\n",
        "        benign_training_errors.append(loss.item())\n",
        "\n",
        "# Calculate threshold based on benign training errors\n",
        "mean_error = np.mean(benign_training_errors)\n",
        "std_error = np.std(benign_training_errors)\n",
        "\n",
        "# Example threshold setting: Mean + 2 standard deviations\n",
        "threshold = mean_error + 2 * std_error\n",
        "\n",
        "\n",
        "print(f\"Calculated threshold based on benign training data: {threshold:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlVMvNjbTATN",
        "outputId": "7fc4e5aa-047b-4b52-d77d-037f2809affe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated threshold based on benign training data: 0.0154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "#Merge benign files\n",
        "\n",
        "benign_file_1 = \"/content/N-BAIoT Dataset/benign/1.benign.csv\"\n",
        "benign_file_2 = \"/content/N-BAIoT Dataset/benign/2.benign.csv\"\n",
        "\n",
        "# Read each CSV file into a pandas DataFrame\n",
        "df_benign_1 = pd.read_csv(benign_file_1)\n",
        "df_benign_2 = pd.read_csv(benign_file_2)\n",
        "\n",
        "# Merge the two DataFrames row-wise\n",
        "# The axis=0 argument specifies concatenation along the rows\n",
        "df_benign = pd.concat([df_benign_1, df_benign_2], ignore_index=True)\n",
        "\n",
        "data_benign, _ = preprocess_data(df_benign)\n",
        "data_benign = np.nan_to_num(data_benign, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "data_benign_t = torch.tensor(data_benign, dtype=torch.float32)\n",
        "labels_benign = torch.zeros(data_benign_t.shape[0], dtype=torch.long) # True label is 0 for benign\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6qeGeaxBjf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the paths to the folders\n",
        "folder_path_1 = \"/content/N-BAIoT Dataset/1\"\n",
        "folder_path_2 = \"/content/N-BAIoT Dataset/2\"\n",
        "\n",
        "# List to hold DataFrames from all files\n",
        "all_dfs = []\n",
        "\n",
        "# Function to read and append CSVs from a folder\n",
        "def read_csvs_from_folder(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                all_dfs.append(df)\n",
        "                print(f\"Read file: {file_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading file {file_path}: {e}\")\n",
        "\n",
        "# Read CSVs from both folders\n",
        "read_csvs_from_folder(folder_path_1)\n",
        "read_csvs_from_folder(folder_path_2)\n",
        "\n",
        "# Concatenate all DataFrames in the list\n",
        "if all_dfs:\n",
        "    df_junk = pd.concat(all_dfs, ignore_index=True)\n",
        "    print(\"\\nSuccessfully merged all anomaly CSV files.\")\n",
        "    print(df_junk.head())\n",
        "else:\n",
        "    print(\"\\nNo CSV files found in the specified folders.\")\n",
        "\n",
        "\n",
        "data_junk, _ = preprocess_data(df_junk) # Discarding the scaler\n",
        "data_junk = np.nan_to_num(data_junk, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "data_junk_t = torch.tensor(data_junk, dtype=torch.float32)\n",
        "labels_junk = torch.ones(data_junk_t.shape[0], dtype=torch.long) # True label is 1 for anamoly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Dib37FgCfiVr",
        "outputId": "7e4b5813-c4c9-4c9a-97bb-b741c5980ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read file: /content/N-BAIoT Dataset/1/1.mirai.scan.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.gafgyt.udp.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.mirai.syn.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.gafgyt.combo.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.mirai.ack.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.gafgyt.tcp.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.gafgyt.scan.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.gafgyt.junk.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.mirai.udp.csv\n",
            "Read file: /content/N-BAIoT Dataset/1/1.mirai.udpplain.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.gafgyt.udp.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.mirai.udpplain.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.mirai.syn.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.gafgyt.combo.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.mirai.ack.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.gafgyt.tcp.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.mirai.udp.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.gafgyt.junk.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.gafgyt.scan.csv\n",
            "Read file: /content/N-BAIoT Dataset/2/2.mirai.scan.csv\n",
            "\n",
            "Successfully merged all anomaly CSV files.\n",
            "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
            "0          1.000000       75.000000            0.000000          1.000000   \n",
            "1          1.106002       61.437635           19.497725          1.260128   \n",
            "2          2.105991       60.754994           10.754895          2.260121   \n",
            "3          3.105975       60.511916            7.416684          3.260111   \n",
            "4          4.105965       60.387240            5.658644          4.260104   \n",
            "\n",
            "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
            "0       75.000000            0.000000          1.000000       75.000000   \n",
            "1       63.096451           36.858761          1.638356       65.844478   \n",
            "2       61.726414           22.915699          2.638352       63.629278   \n",
            "3       61.196857           16.520386          3.638348       62.631771   \n",
            "4       60.915911           12.899777          4.638346       62.064377   \n",
            "\n",
            "   MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_radius  \\\n",
            "0            0.000000            1.000000  ...               0.0   \n",
            "1           53.509247            1.956106  ...               0.0   \n",
            "2           41.267511            2.956106  ...               0.0   \n",
            "3           32.550346            3.956106  ...               0.0   \n",
            "4           26.703999            4.956105  ...               0.0   \n",
            "\n",
            "   HpHp_L0.1_covariance  HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  \\\n",
            "0                   0.0            0.0                1.0             75.0   \n",
            "1                   0.0            0.0                1.0             60.0   \n",
            "2                   0.0            0.0                1.0             60.0   \n",
            "3                   0.0            0.0                1.0             60.0   \n",
            "4                   0.0            0.0                1.0             60.0   \n",
            "\n",
            "   HpHp_L0.01_std  HpHp_L0.01_magnitude  HpHp_L0.01_radius  \\\n",
            "0             0.0                  75.0                0.0   \n",
            "1             0.0                  60.0                0.0   \n",
            "2             0.0                  60.0                0.0   \n",
            "3             0.0                  60.0                0.0   \n",
            "4             0.0                  60.0                0.0   \n",
            "\n",
            "   HpHp_L0.01_covariance  HpHp_L0.01_pcc  \n",
            "0                    0.0             0.0  \n",
            "1                    0.0             0.0  \n",
            "2                    0.0             0.0  \n",
            "3                    0.0             0.0  \n",
            "4                    0.0             0.0  \n",
            "\n",
            "[5 rows x 115 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine the data and labels\n",
        "all_data_t = torch.cat((data_benign_t, data_junk_t), dim=0)\n",
        "true_labels = torch.cat((labels_benign, labels_junk), dim=0)\n"
      ],
      "metadata": {
        "id": "jFs7idn5guYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "#checkpoint_path = 'my_checkpoints/parameters_round_2.pkl'\n",
        "\n",
        "# Load the checkpoint data\n",
        "with open(checkpoint_path, 'rb') as h:\n",
        "    checkpoint_data = pickle.load(h)\n",
        "\n",
        "# Extract the global parameters (list of NumPy arrays)\n",
        "global_parameters_ndarrays = checkpoint_data['globa_parameters']\n",
        "temp_model = Autoencoder(all_data_t.shape[1])\n",
        "state_dict_keys = list(temp_model.state_dict().keys())\n",
        "\n",
        "loaded_state_dict = OrderedDict(zip(state_dict_keys, [torch.tensor(v) for v in global_parameters_ndarrays]))\n",
        "\n",
        "input_dim = all_data_t.shape[1]\n",
        "autoencoder_inference = Autoencoder(input_dim)\n",
        "\n",
        "# Load the state dictionary from the checkpoint\n",
        "autoencoder_inference.load_state_dict(loaded_state_dict)\n",
        "#autoencoder_inference.to(device)\n",
        "autoencoder_inference.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cfbAxV0pOktF",
        "outputId": "d75ed32e-2012-4e26-86e8-0285acc0b54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=115, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Linear(in_features=256, out_features=115, bias=True)\n",
              "    (4): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Calculate Reconstruction Errors\n",
        "reconstruction_errors = []\n",
        "criterion = nn.MSELoss(reduction='none') # Use reduction='none' to get loss per data point\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(all_data_t.shape[0]):\n",
        "        data_point = all_data_t[i].unsqueeze(0)\n",
        "        output = autoencoder_inference(data_point)\n",
        "        # Calculate MSE loss for this data point\n",
        "        loss = criterion(output, data_point).mean() # Mean over features for each data point\n",
        "        reconstruction_errors.append(loss.item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n0AdCIwKBsHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#threshold = 0.0295\n",
        "print(f\"Using threshold: {threshold}\")\n",
        "\n",
        "predicted_anomalies = [1 if error > threshold else 0 for error in reconstruction_errors]\n",
        "predicted_anomalies_t = torch.tensor(predicted_anomalies, dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yHKKn0myBOD",
        "outputId": "d3d5b9f3-f973-46e3-cef6-d9a48499e8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using threshold: 0.015380963695564187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Confusion Matrix and Metrics ---\n",
        "\n",
        "# Ensure both true_labels and predicted_anomalies_t are on CPU and are the same data type (e.g., long)\n",
        "true_labels_np = true_labels.cpu().numpy()\n",
        "predicted_anomalies_np = predicted_anomalies_t.cpu().numpy()\n",
        "\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels_np, predicted_anomalies_np)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate other metrics\n",
        "accuracy = accuracy_score(true_labels_np, predicted_anomalies_np)\n",
        "precision = precision_score(true_labels_np, predicted_anomalies_np, zero_division=0) # Handle case with no positive predictions\n",
        "recall = recall_score(true_labels_np, predicted_anomalies_np, zero_division=0) # Handle case with no actual positives\n",
        "f1 = f1_score(true_labels_np, predicted_anomalies_np, zero_division=0) # Handle case with no positive predictions or actual positives\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFOqOcadR7Bq",
        "outputId": "e74a722c-a4df-4ef8-a24e-c8d075cfa196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "[[  60233    2428]\n",
            " [  18424 1773089]]\n",
            "\n",
            "Accuracy: 0.9888\n",
            "Precision: 0.9986\n",
            "Recall: 0.9897\n",
            "F1-score: 0.9942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a ConfusionMatrixDisplay object\n",
        "# Define the display labels (optional, but good practice)\n",
        "display_labels = [\"Benign\", \"Junk\"]\n",
        "\n",
        "# Create the ConfusionMatrixDisplay object\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "disp.plot(cmap=plt.cm.Blues) # You can choose a different colormap\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SxSkylaoZi84",
        "outputId": "c7183b16-19b5-485c-a94c-e26fc9c28b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}